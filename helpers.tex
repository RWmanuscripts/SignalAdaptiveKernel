%% LyX 2.4.3 created this file.  For more info, see https://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[american]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{babel}
\begin{document}
The hyperparameters in the numerical experiments are fitted by the negative ML objective (Eq. 4) for non-lazy-evaluation models, and by the data reduction method from Section 4.2 for lazy-evaluation models. Grid-based data such as grayscale images are used to facilitate easier visualization and interpretation for the continuity properties of the lazy-evaluation inference model and the ability to emphasize contours of the proposed warp map. Our work is meant to be a step towards regression modeling of non-grid-based observation data whilst carrying over some of these continuity and contour-preserving properties that are achievable by alternative methods for grid-based observations.

In Section 5.1, we visualize and interpret the proposed family of dimensional expansion kernels from Section 3. In Section 5.2, we visualize continuity-related issues for the patchwork kriging model, considered to be a state-of-the-art local GPR method. In section 5.3, we examine the lazy-evaluation combined with DE kernel on a set of grayscale images, to see there are no visually noticeable continuity-related issues and that contours are slightly better emphasized as discussed in Section 5.1. We use the conventional GPR inference (i.e., non-lazy-evaluation) with the DE kernel in Sections 5.4 and 5.5 to examine the smoothing and the reduced oscillations of the predictive posterior for non-grid-based real-world rainfall and geology elevation datasets. We conclude this section with timing benchmarks of the methods used in our numerical experiments.

\section{Dimensional expansion kernel}

We discussed the construction of two sets of warp samples: the HWRT-based samples from Eq. 12 can only be made from grid-based data, and have issues near the boundary of the data, as shown in Fig 3. The BF-based samples from Eq. 17 can be constructed from grid-based and non-grid-based data, and the numerical experiments are carried out with the BF-based warp map. The warp maps formed from these two sets of samples are shown in Fig. 6 (smaller image size, make into one fig because emphasis is no longer on HRWT vs BF).

Fig markers show two markers on an image, which is taken to be the observations to a non-lazy-evaluation GPR model. The diamond marker is near an edge in the image, and the star marker is in an area with little edges. The last row of plots in Fig. are the show the difference between the stationary kernel and the dimensional kernel when one kernel input is taken to be a marker. The other input of the kernel is taken to be the neighboring locations near the marker. The presence of a non-zero warp map for the neighborhood near the diamond marker help shape the footprint of the kernel centered at marker to adjust to the contours of the warp map. The star marker is in a neighborhood where the warp map evaluates to near zero, so the dimensional expansion kernel centered at that marker is nearly the same as the canonical kernel.

\section{Patchwork kriging: continuity issues}

A state-of-the-art local GPR model is Patchwork Kriging, where the input space is partitioned by some given spatial or k-d tree to form local models. It relies on a given set of points, called \emph{pseudo observations}, that must lie on the boundary of two local models. The pseudo observations must be given before query-time, and queries near the boundary of two local models are not in general discontinuous unless the query point is a pseudo observation. In practice, this meant query points on a boundary that have many nearby pseudo observations is likely to exhibit a smaller discontinuity step than the case where there is little nearby pseudo observations. We illustrate this issue in Fig pw\_issues with a synthetic 2D dataset and a minimal setup of patchwork kriging as well as the conventional GPR method.

\section{Kodak Image Suite}

The Kodak Image Suite dataset contains 24 images, and image up-conversion is a good visual method to inspect a regression method's performance, especially concerning continuity and the handling of edges in the input image. We take the grayscale version of the database images to be the \emph{reference} images. The grid-based observation data was taken to be the reference down-sampled by two, i.e., every other pixel is discarded. The query positions are taken to be the positions occupied by the pixels in the reference, i.e., the up-conversion factor is two. This setup allows us to quantify image similarity between the reference and our results via the \emph{Structural Similarity Index Measure} (SSIM) {[}ref{]}. Since the observation data is too large for conventional GPR inference, we used the lazy-evaluation method. Unlike patchwork kriging, Theorem 4.x ensures our lazy-evaluation method should have valid continuity behavior everywhere on the input space. There are no visually noticeable discontinuous steps in the up-conversion results in Figs blah-blah.

Although the HRWT-based warp map can be used on image data, we use the BF-based warp map so we get good visualization of its behavior, before we use BF for non-grid data in the next experiment. Recall that our axis-search... (rest of paragraph)

The discarding of pixels... (entire rest of subsection)

\section{Rainfall measurements}

Fig 7 shows the rainfall measurement for some Canadian weather stations near the city of Ottawa, Ontario on August 10, 2023. The city of Ottawa experience significant rainfall but some nearby regions got little rain. This dataset provides a good demonstration for Runge and Gibbs-like oscillatory phenomenon for regression methods. The original data source was taken from the National Oceanic and Atmospheric Administration's (NOAA) Global Historical Climatology Network Daily dataset. This dataset was not large enough to require the use of lazy-evaluation GPR, so conventional GPR with DE kernel was used for this analysis. We did not experience the joint hyperparameters optimization issue from the Kodak experiments, so the two-stage optimization approach from Section 5.3 was not used here.

The hyperparameters for the DE kernel ... (rest of subsection)

\section{Lidar topographic measurements}

Light detection and ranging (LiDAR) is a remote sensing technique that can be used to develop digital elevation models of land surface, which are used by power utilities, transportation infrastructure builders, and telecommunication companies to plan development projects. The LiDAR sensor might be on a satellite or aircraft, so the sampling pattern on the land does not always result in a grid. It is common to have regions with little LiDAR measurements because some wavelengths are absorbed by water or vegetation, and the measured range signal can appear noisy for some materials. For this reason, uncertainty information from regression models could potentially provide useful information to the users of LiDAR-based digital elevation models. We used a subset of the Missisquoi Watershed LiDAR dataset {[}{]} from OpenTopography to compare the result of the DE kernel with Natural Neighbors Sibson and inverse distance weighting, which are popular regression techniques in the applied topography community. The Julia packages NaturalNeighbours.jl and ScatteredInterpolations.jl were used for producing the Natural Neighbors Sibson and inverse distance weighting results, respectively. Lazy-evaluation GPR was not used in this experiment, as conventional GPR was tractable for the size of the dataset we used. The two-stage hyperparameter fitting approach from Sec. 5.2 was used.

The left-most plot from Fig elevation\_query illustrate the location of the LiDAR measurements, and the noisy scan-line sampling pattern that is probably due to the LiDAR satellite's trajectory are noticeable in the high elevation (i.e., bright) portions of the queried results. The stationary kernel results removed the noisy appearance, but lost most of the details of the image. The inverse distance weighting and Sibson methods preserved the details, but have a lack of smoothing.

The predictive variance of the DE kernel's result have some larger values in regions that correspond to the noisy high elevation measurements. The Sibson and inverse distance weighting plots show a smooth region in the bottom right section, and the user would not be able to access whether the model is well-represented there or that there area lack of measurements in the region. Predictive posterior variance could be useful for users of elevation models so that subsequent remote sensing efforts with a different LiDAR wavelength can be allocated to measure the regions with high uncertainty of the regression model.

\section{Time benchmarks}

We made a few trade-offs in the design of the proposed warp map-based DE kernels and lazy-evaluation inference works. The DE kernels require additional resources to evaluate the warp map for every query point, but the warp map evaluations for the training inputs can be pre-computed and stored in memory to speed up the computation of kernel matrices $K_{X,X}$ that involve subsets of the set of training inputs $X$. The computational complexity of the warp map extrapolation method adds to the overall time complexity of a GPR model that uses a DE kernel. We used the inverse distance weighting interpolation/extrapolation method to turn the warp samples into a warp map, which has a time-complexity of $O\left(N\right)$, where $N$ is the number of observations.

Computing the predictive mean can be significantly faster than the predictive variance for the conventional GPR predictive posterior when $N$ is large. This is because the $\left(K_{X,X}+\sigma^{2}I\right)^{-1}y$ portion of Eq blah can be pre-computed for any query location $x^{*}$, but a linear system that involves the query location needs to be solved in Eq. blah. Present day mainstream implementations of numerical linear system solvers have a time complexity of $O\left(N^{3}\right)$. The proposed lazy-evaluation approach replaces $N$ with the size of $U$, which is the set of observations in the query location's neighborhood of a given radius. Since $U$ depends on the query location, the vector $\left(K_{U,U}+\sigma^{2}I\right)^{-1}y$ cannot be pre-computed for any query location. This implies that when lazy-evaluation GPR will gradually lose its time-complexity advantage as the number of query points increase, and eventually be slower than conventional GPR. The size of $U$ also depends on the radius of the local neighborhood, and the number of training inputs in a query location's neighborhood, making this topic difficult to study. For this reason, our benchmarks on computing the predictive posterior are for only one query location. An in-depth complexity analysis as a function of all possible types of query point neighborhoods and query point numbers for the lazy-evaluation GPR is out of the scope of this work.

For all the benchmarks, we used a grayscale image that is small enough for conventional GPR and a query location that is within the image coordinate bounds. This is because for grid-based data, the size of $U$ should be similar for any interior query points away from the boundary of the grid. We cropped a region of an image from the Kodak Image Suite, and down-sampled it by different factors to get an image of size $\left(95,105\right)$, $\left(48,53\right)$, and $\left(32,35\right)$ pixels. The lazy-evaluation GPR model used the data reduction strategy from Sec 4.2 to fit its hyperparameters. The tuning parameter $M$ from section 4.2 is an upper bound of the number of training entries to use, and Table hp\_table showcase how different $M$ affect the time it took to fit the hyperparameters. A radius of $6$ pixels was used for the lazy-evaluation models in this table, similar to what was used in the image up-conversion experiment from Sec 5.2. We see the lazy-evaluation data reduction method offers significantly shorter times than the conventional GPR. For reference, $M$ was set to $50$ for the experiments done in Sec 5.2.

Table con\_query shows the times for computing the predictive posterior (both), just the predictive posterior mean (mean), and the pre-computation of the $\left(K_{X,X}+\sigma^{2}I\right)^{-1}y$ vector (setup) for the conventional GPR model. The analogous results for the lazy-evaluation GPR are shown in Table lazy\_query, where the image size was set to $\left(95,105\right)$ because the size does not affect query speed. The neighborhood size is controlled by the local model radius, and this table shows it significantly affects the computation times.

In these tables, larger image sizes result in significantly longer computation times for both hyper parameter fitting and predictive posterior computation. The DE kernel was not significantly slower than the stationary kernel times for all tables. Some time benchmarks for other non-GPR regression or interpolation methods are shown in Table non\_gpr. The bi-cubic $B$-spline method only works for grid-based data, but is very fast. The inverse distance weighting method can be used for non-grid based data, and requires no setup. The image with size $\left(95,105\right)$ was used for this table. The GPR methods are still quite slow than these alternative methods, but the predictive posterior variance information can be useful for applications such as spatial climate data or topological elevation modeling.
\end{document}
