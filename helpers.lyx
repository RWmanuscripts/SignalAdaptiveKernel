#LyX 2.4 created this file. For more info see https://www.lyx.org/
\lyxformat 620
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children no
\language american
\language_package default
\inputencoding utf8
\fontencoding auto
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_roman_osf false
\font_sans_osf false
\font_typewriter_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\float_placement class
\float_alignment class
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_formatted_ref 0
\use_minted 0
\use_lineno 0
\index Index
\shortcut idx
\color #718c00
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tablestyle default
\tracking_changes false
\output_changes false
\change_bars false
\postpone_fragile_content true
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\docbook_table_output 0
\docbook_mathml_prefix 1
\end_header

\begin_body

\begin_layout Standard
The kernel from the warp GP family of works has the form 
\begin_inset Formula 
\begin{align*}
k:\mathbb{R}^{D}\times\mathbb{R}^{D} & \rightarrow\mathbb{R}\\
\left(x,z\right) & \mapsto k_{\text{s}}\left(g\left(x\right),g\left(z\right)\right),
\end{align*}

\end_inset

 where 
\begin_inset Formula $g$
\end_inset

 is a function to be learned.
 For example,
 
\begin_inset Formula $g$
\end_inset

 is a neural network in the 
\emph on
deep kernel learning
\emph default
 (DKL) family of works [].
 Recent analysis...
 The fact that the dimensional expansion kernel ensures the original inputs,
 
\begin_inset Formula $x$
\end_inset

 and 
\begin_inset Formula $z$
\end_inset

 appear explicitly in 
\begin_inset Formula $k$
\end_inset

 allowed us to design a hyperparameter optimization strategy that circumvents the issues of hyperparameter inference from the DKL work.
 The 
\begin_inset Formula $\phi$
\end_inset

 that we propose in the dimensional expansion kernel framework only has a few interpretable hyperparameters to tune,
 whereas the flexibility of having an arbitrary 
\begin_inset Formula $g$
\end_inset

 from the more generic warp GP formulation typically requires more hyperparameters (i.e.,
 a neural network for 
\begin_inset Formula $g$
\end_inset

) or objective function-related learning generalization issues as suggested in [].
\end_layout

\end_body
\end_document
